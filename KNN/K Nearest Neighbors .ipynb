{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a8f34ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b817fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNRegression:\n",
    "    def __init__ (self, X, Y, k):\n",
    "        self.k = k\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "    \n",
    "    def EuclidieanDistance (self, x1):\n",
    "        if self.train == True:\n",
    "            self.x2 = self.X[self.idx]\n",
    "        else: \n",
    "            self.x2 = self.x_test\n",
    "        distance = np.sqrt(np.sum(np.square(x1-self.x2)))\n",
    "        return distance\n",
    "    \n",
    "    def calc_neighbors(self):\n",
    "        costs = np.apply_along_axis(self.EuclidieanDistance, 1, self.X)\n",
    "        sorted_costs = np.sort(costs)\n",
    "        indices = np.where(costs <= sorted_costs[self.k-1])[0]\n",
    "        return indices\n",
    "    \n",
    "    def predictions(self, indices):\n",
    "        prediction = float(0)\n",
    "        for i in indices:\n",
    "            prediction += self.Y[i]\n",
    "        prediction = prediction / indices.shape\n",
    "        return float(prediction)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        self.train = False\n",
    "        self.x_test = x\n",
    "        indices =  self.calc_neighbors()\n",
    "        print(indices)\n",
    "        return self.predictions(indices)\n",
    "    \n",
    "    def accuracy(self, x_test_set, y_test_set):\n",
    "        y_pred = []\n",
    "        for i in  range(x_test_set.shape[0]):\n",
    "            self.train = False\n",
    "            self.x_test = x_test_set[i]\n",
    "            indices =  self.calc_neighbors()\n",
    "            y_pred.append(self.predictions(indices))\n",
    "        ssr = np.sum((y_pred - y_test_set)**2)\n",
    "        sst = np.sum((y_test_set - y_test_set.mean())**2)\n",
    "        self.r2_score = 1 - (ssr/sst)\n",
    "        return self.r2_score, y_pred\n",
    "        \n",
    "    def propogate(self):\n",
    "        y_pred = []\n",
    "        self.train = True\n",
    "        for i in range(self.X.shape[0]):\n",
    "            self.idx = i\n",
    "            indices =  self.calc_neighbors()\n",
    "            y_pred.append(self.predictions(indices))\n",
    "        print(\"Model Trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc0d3dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3) (3,)\n",
      "Model Trained\n",
      "(2, 3) (2, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1.08, [2.5, 2.5])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 1, 1], [3, 3, 3], [2, 2, 2]])\n",
    "\n",
    "b = np.array([1, 3, 2])\n",
    "print(a.shape, b.shape)\n",
    "a = KNNRegression(a, b, 2)\n",
    "a.propogate()\n",
    "temp_1 = np.array([[3.1, 3.1, 3.1], [2.1, 2.1, 2.1]])\n",
    "temp_2 = np.array([[3.1], [2.1]])\n",
    "print(temp_1.shape, temp_2.shape)\n",
    "a.accuracy(np.array([[3.1, 3.1, 3.1], [2.1, 2.1, 2.1]]), np.array([[3.1], [2.1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf4e93a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.predict(np.array([[3.1, 3.1, 3.1], [2.1, 2.1, 2.1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88b45b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(530, 15)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "# Changing all yes/no data to 0/1, normalization of price and area, and outlier removal \n",
    "df = pd.read_csv('Housing.csv')\n",
    "for column in df:  \n",
    "    df[column].replace(('yes','no'), (0,1), inplace = True)\n",
    "    if(column == 'area'):\n",
    "        df[column] = (df[column] - df[column].mean()) / df[column].std()\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        df.drop(df[(df[column] < Q1-1.5*IQR) | (df[column] > Q3+1.5*IQR)].index, inplace = True) \n",
    "        \n",
    "# Adding One Hot Encoding to furnishingstatus \n",
    "\n",
    "df = pd.get_dummies(df, columns = ['furnishingstatus']) \n",
    "\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "368af2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(530, 1)\n",
      "(530, 14)\n"
     ]
    }
   ],
   "source": [
    "Y = np.array(df.iloc[:, 0:1])\n",
    "print(Y.shape)\n",
    "X = np.array(df.iloc[:, 1:])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4c709be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 477) (14, 53) (1, 477) (1, 53)\n"
     ]
    }
   ],
   "source": [
    "def split_data(X, Y, test_size=0.1, random_state=42):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = test_size, random_state = 42)\n",
    "    x_train = np.array(x_train.T)\n",
    "    x_test = np.array(x_test.T)\n",
    "    y_train = np.array(y_train.T)\n",
    "    y_test = np.array(y_test.T)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test  = split_data(X, Y)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e51d53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained\n"
     ]
    }
   ],
   "source": [
    "model = KNNRegression(x_train, y_train.T, 5)\n",
    "model.propogate()\n",
    "r2_score, predictions = model.accuracy(x_train, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c4d2e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:, 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f72a858a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 53)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdfa1f54",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [14, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Saatwik V\\Documents\\Repositories\\machine_learning\\KNN\\K Nearest Neighbors .ipynb Cell 11\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Saatwik%20V/Documents/Repositories/machine_learning/KNN/K%20Nearest%20Neighbors%20.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_squared_error \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Saatwik%20V/Documents/Repositories/machine_learning/KNN/K%20Nearest%20Neighbors%20.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(mean_squared_error(predictions, y_test))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_regression.py:442\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean_squared_error\u001b[39m(\n\u001b[0;32m    383\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, multioutput\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39muniform_average\u001b[39m\u001b[39m\"\u001b[39m, squared\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    384\u001b[0m ):\n\u001b[0;32m    385\u001b[0m     \u001b[39m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \n\u001b[0;32m    387\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39m    0.825...\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[39m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    443\u001b[0m         y_true, y_pred, multioutput\n\u001b[0;32m    444\u001b[0m     )\n\u001b[0;32m    445\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    446\u001b[0m     output_errors \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maverage((y_true \u001b[39m-\u001b[39m y_pred) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, weights\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_regression.py:100\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     67\u001b[0m     \u001b[39m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \n\u001b[0;32m     69\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39m        correct keyword.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[0;32m    101\u001b[0m     y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    102\u001b[0m     y_pred \u001b[39m=\u001b[39m check_array(y_pred, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [14, 1]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "print(mean_squared_error(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d17698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8e284ee3255a07ad8bf76694974743c4c81cb57e7c969474d752d949b11d721e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
